{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon\n",
    "import os\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SCHOOLS_DATA_DIR = '/Users/atalya/Documents/anyway_main/repos/anyway/static/data/schools/all_schools_data_orig/csvs/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_years = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(ALL_SCHOOLS_DATA_DIR, \"*.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(all_files) == 4886)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['inv_unique_id'] = df['provider_and_id'].astype(str) + '_' +  df['involve_id'].astype(str) + '_' + df['accident_year'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['acc_unique_id'] = df['provider_and_id'].astype(str) + '_' + df['accident_year'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_or_pedestrian'] = df.apply(lambda x: x['involve_vehicle_type_hebrew'] if x['injured_type_hebrew'] != 'הולך רגל' else  x['injured_type_hebrew'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['accident_timestamp'] = pd.to_datetime(df['accident_timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Yom Kippur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import holidays\n",
    "yom_kippuer_dates = []\n",
    "for date, name in sorted(holidays.IL(years=range(2013,2023)).items()):\n",
    "    if \"Yom Kippur\" in name:\n",
    "        yom_kippuer_dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(yom_kippuer_dates) == total_number_of_years * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~(df.accident_timestamp.dt.date.isin(yom_kippuer_dates))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not(df.accident_timestamp.dt.date.isin(yom_kippuer_dates).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_dict = {1: 'ינואר', \n",
    "               2: 'פברואר',\n",
    "               3: 'מרס',\n",
    "               4: 'אפריל',\n",
    "               5: 'מאי',\n",
    "               6: 'יוני',\n",
    "               7: 'יולי',\n",
    "               8: 'אוגוסט',\n",
    "               9: 'ספטמבר',\n",
    "               10: 'אוקטובר',\n",
    "               11: 'נובמבר',\n",
    "               12: 'דצמבר'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['accident_month_hebrew'] = df['accident_month'].apply(lambda m: months_dict.get(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to last 5 years and first 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_5_years_start = pd.Timestamp(year=2018, month=7, day=1).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_5_years = df.loc[(df.accident_timestamp.dt.date < first_5_years_start)].copy()\n",
    "df_last_5_years = df.loc[(df.accident_timestamp.dt.date >= first_5_years_start)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_years = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(round(((df['accident_timestamp'].max() - df['accident_timestamp'].min()).days / 365),0) == total_number_of_years)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta = (df['accident_timestamp'].max() - df['accident_timestamp'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(isclose(timedelta.days / (365.25),10, abs_tol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['accident_timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['accident_timestamp'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create results dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_2023_results_directory = 'schools_2023_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(schools_2023_results_directory):\n",
    "    os.mkdir(schools_2023_results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(schools_2023_results_directory,'all_injured_per_schools.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_injured = df.drop_duplicates('inv_unique_id').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_injured.to_csv(os.path.join(schools_2023_results_directory,'all_unique_injured.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools = df.groupby(['injury_severity'])[\"inv_unique_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools.to_csv(os.path.join(schools_2023_results_directory,'df_injured_in_all_schools.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_v_or_p = df.groupby(['injury_severity', 'vehicle_or_pedestrian'])[\"inv_unique_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_v_or_p.to_csv(os.path.join(schools_2023_results_directory,'df_injured_in_all_schools_per_type.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_p_c = df.groupby(['injury_severity', 'provider_code'])[\"inv_unique_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_p_c.to_csv(os.path.join(schools_2023_results_directory,'df_injured_in_all_schools_per_p_c.csv'), index=False)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_v_or_p_first_5_years = df_first_5_years.groupby(['injury_severity_hebrew', 'vehicle_or_pedestrian'])[\"inv_unique_id\"].nunique().to_frame()\n",
    "df_injured_in_all_schools_per_v_or_p_first_5_years.columns = ['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_v_or_p_first_5_years.to_csv(os.path.join(schools_2023_results_directory,'df_injured_first_5_years_per_severity_vehicle_pedestrian.csv'), index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_v_or_p_last_5_years = df_last_5_years.groupby(['injury_severity_hebrew', 'vehicle_or_pedestrian'])[\"inv_unique_id\"].nunique().to_frame()\n",
    "df_injured_in_all_schools_per_v_or_p_last_5_years.columns = ['count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_injured_in_all_schools_per_v_or_p_last_5_years.to_csv(os.path.join(schools_2023_results_directory,'df_injured_last_5_years_per_severity_vehicle_pedestrian.csv'), index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "killed_weight = 6600/7581\n",
    "severe_weight = 956/7581\n",
    "light_weight = 25/7581"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calc pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_pedestrians = df_unique_injured.loc[df_unique_injured.vehicle_or_pedestrian == 'הולך רגל'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_pedestrians.loc[df_only_pedestrians['cross_mode_hebrew'].isna(), 'cross_mode_hebrew'] = 'למס לא סיפקו נתונים'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_pedestrians.loc[df_only_pedestrians['didnt_cross_hebrew'].isna(), 'didnt_cross_hebrew'] = 'למס לא סיפקו נתונים'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_only_pedestrians.loc[df_only_pedestrians['cross_location_hebrew'].isna(), 'cross_location_hebrew'] = 'למס לא סיפקו נתונים'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maavar = df_only_pedestrians.groupby(['injury_severity_hebrew','cross_location_hebrew']).size().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maavar.to_csv(os.path.join(schools_2023_results_directory,'df_maavar_pedestrians.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calc per school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_injured_schools = (\n",
    "    df_last_5_years.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"school_id\",\n",
    "            \"school_name\",\n",
    "            \"institution_type\",\n",
    "            \"school_anyway_link\",\n",
    "            \"school_longitude\",\n",
    "            \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "            \"injury_severity\"\n",
    "        ]\n",
    "    )\n",
    "    .size()\n",
    "    .reset_index(name=\"injured_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"school_id\",\n",
    "            \"school_name\",\n",
    "            \"institution_type\",\n",
    "            \"school_anyway_link\",\n",
    "            \"injury_severity\",\n",
    "            \"injured_count\",\n",
    "            \"school_longitude\",\n",
    "            \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "df_total_injured_schools = df_total_injured_schools.set_index(\n",
    "    [\n",
    "        \"school_yishuv_name\",\n",
    "        \"school_id\",\n",
    "        \"school_name\",\n",
    "        \"institution_type\",\n",
    "        \"school_anyway_link\",\n",
    "        \"school_longitude\",\n",
    "        \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "        \"injury_severity\",\n",
    "\n",
    "    ]\n",
    ").unstack(-1)\n",
    "df_total_injured_schools.fillna({\"injured_count\": 0, \"total_injured_count\": 0}, inplace=True)\n",
    "\n",
    "df_total_injured_schools.loc[:, (slice(\"injured_count\"), slice(None))] = df_total_injured_schools.loc[\n",
    "    :, (slice(\"injured_count\"), slice(None))\n",
    "].apply(lambda x: x.apply(int))\n",
    "\n",
    "df_total_injured_schools[\"total_injured_count\"] = (\n",
    "    df_total_injured_schools.loc[:, [\"injured_count\"]].sum(axis=1)\n",
    ").apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_injured_schools.columns = ['killed_count', 'severe_injured_count', 'light_injured_count', 'total_injured_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_injured_per_veh_or_ped = (\n",
    "    df_last_5_years.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"school_id\",\n",
    "            \"school_name\",\n",
    "            \"institution_type\",\n",
    "            \"school_anyway_link\",\n",
    "            \"school_longitude\",\n",
    "            \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "            \"vehicle_or_pedestrian\"\n",
    "        ]\n",
    "    )\n",
    "    .size()\n",
    "    .reset_index(name=\"injured_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"school_id\",\n",
    "            \"school_name\",\n",
    "            \"institution_type\",\n",
    "            \"school_anyway_link\",\n",
    "            \"vehicle_or_pedestrian\",\n",
    "            \"injured_count\",\n",
    "            \"school_longitude\",\n",
    "            \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "df_total_injured_per_veh_or_ped = df_total_injured_per_veh_or_ped.set_index(\n",
    "    [\n",
    "        \"school_yishuv_name\",\n",
    "        \"school_id\",\n",
    "        \"school_name\",\n",
    "        \"institution_type\",\n",
    "        \"school_anyway_link\",\n",
    "        \"school_longitude\",\n",
    "        \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "        \"vehicle_or_pedestrian\",\n",
    "\n",
    "    ]\n",
    ").unstack(-1)\n",
    "\n",
    "df_total_injured_per_veh_or_ped.fillna({\"injured_count\": 0, \"total_injured_count\": 0}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_injured_per_veh_or_ped.columns = ['bike', 'electric_bike', 'pedestrians', 'electric_korki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_accidents_schools = (\n",
    "    df_last_5_years.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"school_id\",\n",
    "            \"school_name\",\n",
    "            \"institution_type\",\n",
    "            \"school_anyway_link\",\n",
    "            \"school_longitude\",\n",
    "            \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "        ]\n",
    "    )[\"acc_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"accidents_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"school_id\",\n",
    "            \"school_name\",\n",
    "            \"institution_type\",\n",
    "            \"school_anyway_link\",\n",
    "            \"school_longitude\",\n",
    "            \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\",\n",
    "            \"accidents_count\"\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_total_accidents_schools = df_total_accidents_schools.set_index(\n",
    "[\n",
    "        \"school_yishuv_name\",\n",
    "        \"school_id\",\n",
    "        \"school_name\",\n",
    "        \"institution_type\",\n",
    "        \"school_anyway_link\",\n",
    "        \"school_longitude\",\n",
    "        \"school_latitude\",\n",
    "            \"WKT Polygon\",\n",
    "            \"WKT Point_12\",\n",
    "            \"WKT Point_6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.merge(df_total_injured_schools,\n",
    "                     df_total_accidents_schools,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.merge(df_total,\n",
    "                     df_total_injured_per_veh_or_ped,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prat_score(x):\n",
    "    prat_score = (x[\"killed_count\"] + x[\"severe_injured_count\"] + x[\"light_injured_count\"]) * \\\n",
    "   (x[\"killed_count\"] * killed_weight + \\\n",
    "    x[\"severe_injured_count\"]  * severe_weight + \\\n",
    "    x[\"light_injured_count\"]  * light_weight)\n",
    "    return prat_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_heuristic_score(x):\n",
    "    h_score = x[\"killed_count\"] * 8 + \\\n",
    "    x[\"severe_injured_count\"]  * 5 + \\\n",
    "    x[\"light_injured_count\"]  * 1\n",
    "    return h_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['prat_score'] = df_total.apply(lambda x: calc_prat_score(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['h_score'] = df_total.apply(lambda x: calc_heuristic_score(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.sort_values('prat_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(os.path.join(schools_2023_results_directory,'scores_per_school_both_tik1_and_tik3_last_5_years.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calc per yisuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_injured = (\n",
    "    df_last_5_years.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"injury_severity\"\n",
    "        ]\n",
    "    )[\"inv_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"injured_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"injury_severity\",\n",
    "            \"injured_count\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "df_total_injured = df_total_injured.set_index(\n",
    "    [\n",
    "        \"school_yishuv_name\",\n",
    "        \"injury_severity\",\n",
    "\n",
    "    ]\n",
    ").unstack(-1)\n",
    "df_total_injured.fillna({\"injured_count\": 0, \"total_injured_count\": 0}, inplace=True)\n",
    "\n",
    "\n",
    "df_total_injured.loc[:, (slice(\"injured_count\"), slice(None))] = df_total_injured.loc[\n",
    "    :, (slice(\"injured_count\"), slice(None))\n",
    "].apply(lambda x: x.apply(int))\n",
    "\n",
    "df_total_injured[\"total_injured_count\"] = (\n",
    "    df_total_injured.loc[:, [\"injured_count\"]].sum(axis=1)\n",
    ").apply(int)\n",
    "\n",
    "df_total_accidents_yishuvs = (\n",
    "    df_last_5_years.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "        ]\n",
    "    )[\"acc_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"accidents_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"accidents_count\"\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_total_accidents_yishuvs = df_total_accidents_yishuvs.set_index(\n",
    "[\n",
    "        \"school_yishuv_name\"])\n",
    "\n",
    "df_total_yishuvs = pd.merge(df_total_injured,\n",
    "                     df_total_accidents_yishuvs,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how='left')\n",
    "\n",
    "df_total_yishuvs.columns = ['killed_count', 'severe_injured_count', 'light_injured_count', 'total_injured_count', 'accidents_count']\n",
    "\n",
    "df_total_yishuvs['prat_score'] = df_total_yishuvs.apply(lambda x: calc_prat_score(x), axis=1)\n",
    "\n",
    "df_total_yishuvs['h_score'] = df_total_yishuvs.apply(lambda x: calc_heuristic_score(x), axis=1)\n",
    "\n",
    "df_total_yishuvs = df_total_yishuvs.sort_values('prat_score', ascending=False)\n",
    "\n",
    "# calc per 'bike', 'electric_bike', 'pedestrians', 'electric_korki'\n",
    "\n",
    "df_injured_per_yishuv_veh_or_ped = (\n",
    "    df_last_5_years.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"vehicle_or_pedestrian\"\n",
    "        ]\n",
    "    )[\"inv_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"injured_count_per_type\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"injured_count_per_type\",\n",
    "            \"vehicle_or_pedestrian\",\n",
    "\n",
    "        ],\n",
    "    ])\n",
    "\n",
    "\n",
    "df_injured_per_yishuv_veh_or_ped = df_injured_per_yishuv_veh_or_ped.set_index(\n",
    "    [\n",
    "            \"school_yishuv_name\",\n",
    "            \"vehicle_or_pedestrian\",\n",
    "    ]\n",
    ").unstack(-1)\n",
    "\n",
    "df_injured_per_yishuv_veh_or_ped.fillna({\"injured_count_per_type\": 0}, inplace=True)\n",
    "\n",
    "df_injured_per_yishuv_veh_or_ped.columns = ['bike', 'electric_bike', 'pedestrians', 'electric_korki']\n",
    "\n",
    "\n",
    "df_total_yishuvs = pd.merge(df_total_yishuvs,\n",
    "                     df_injured_per_yishuv_veh_or_ped,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_yishuvs.to_csv(os.path.join(schools_2023_results_directory,'scores_per_yishuv_both_tik1_and_tik3_last_5_years.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_yishuvs = df_total_yishuvs['prat_score'].sort_values(ascending=False).iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_yishuvs = top_20_yishuvs.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calc per yisuv and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df_first_5_years.copy()\n",
    "\n",
    "df_total_injured = (\n",
    "    curr_df.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"injury_severity\"\n",
    "        ]\n",
    "    )[\"inv_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"injured_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"injury_severity\",\n",
    "            \"injured_count\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "df_total_injured = df_total_injured.set_index(\n",
    "    [\n",
    "        \"school_yishuv_name\",\n",
    "        \"injury_severity\",\n",
    "\n",
    "    ]\n",
    ").unstack(-1)\n",
    "df_total_injured.fillna({\"injured_count\": 0, \"total_injured_count\": 0}, inplace=True)\n",
    "\n",
    "\n",
    "df_total_injured.loc[:, (slice(\"injured_count\"), slice(None))] = df_total_injured.loc[\n",
    "    :, (slice(\"injured_count\"), slice(None))\n",
    "].apply(lambda x: x.apply(int))\n",
    "\n",
    "df_total_injured[\"total_injured_count\"] = (\n",
    "    df_total_injured.loc[:, [\"injured_count\"]].sum(axis=1)\n",
    ").apply(int)\n",
    "\n",
    "df_total_accidents_yishuvs = (\n",
    "    curr_df.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "        ]\n",
    "    )[\"acc_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"accidents_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"accidents_count\"\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_total_accidents_yishuvs = df_total_accidents_yishuvs.set_index(\n",
    "[\n",
    "        \"school_yishuv_name\"])\n",
    "\n",
    "df_total_yishuvs_first_5_years = pd.merge(df_total_injured,\n",
    "                     df_total_accidents_yishuvs,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how='left')\n",
    "\n",
    "df_total_yishuvs_first_5_years.columns = ['killed_count', 'severe_injured_count', 'light_injured_count', 'total_injured_count', 'accidents_count']\n",
    "\n",
    "df_total_yishuvs_first_5_years['prat_score'] = df_total_yishuvs_first_5_years.apply(lambda x: calc_prat_score(x), axis=1)\n",
    "\n",
    "df_total_yishuvs_first_5_years['h_score'] = df_total_yishuvs_first_5_years.apply(lambda x: calc_heuristic_score(x), axis=1)\n",
    "\n",
    "df_total_yishuvs_first_5_years = df_total_yishuvs_first_5_years.sort_values('prat_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_df = df_last_5_years.copy()\n",
    "\n",
    "df_total_injured = (\n",
    "    curr_df.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"injury_severity\"\n",
    "        ]\n",
    "    )[\"inv_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"injured_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"injury_severity\",\n",
    "            \"injured_count\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "df_total_injured = df_total_injured.set_index(\n",
    "    [\n",
    "        \"school_yishuv_name\",\n",
    "        \"injury_severity\",\n",
    "\n",
    "    ]\n",
    ").unstack(-1)\n",
    "df_total_injured.fillna({\"injured_count\": 0, \"total_injured_count\": 0}, inplace=True)\n",
    "\n",
    "\n",
    "df_total_injured.loc[:, (slice(\"injured_count\"), slice(None))] = df_total_injured.loc[\n",
    "    :, (slice(\"injured_count\"), slice(None))\n",
    "].apply(lambda x: x.apply(int))\n",
    "\n",
    "df_total_injured[\"total_injured_count\"] = (\n",
    "    df_total_injured.loc[:, [\"injured_count\"]].sum(axis=1)\n",
    ").apply(int)\n",
    "\n",
    "df_total_accidents_yishuvs = (\n",
    "    curr_df.groupby(\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "        ]\n",
    "    )[\"acc_unique_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"accidents_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_yishuv_name\",\n",
    "            \"accidents_count\"\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_total_accidents_yishuvs = df_total_accidents_yishuvs.set_index(\n",
    "[\n",
    "        \"school_yishuv_name\"])\n",
    "\n",
    "df_total_yishuvs_last_5_years = pd.merge(df_total_injured,\n",
    "                     df_total_accidents_yishuvs,\n",
    "                     left_index=True,\n",
    "                     right_index=True,\n",
    "                     how='left')\n",
    "\n",
    "df_total_yishuvs_last_5_years.columns = ['killed_count', 'severe_injured_count', 'light_injured_count', 'total_injured_count', 'accidents_count']\n",
    "\n",
    "df_total_yishuvs_last_5_years['prat_score'] = df_total_yishuvs_last_5_years.apply(lambda x: calc_prat_score(x), axis=1)\n",
    "\n",
    "df_total_yishuvs_last_5_years['h_score'] = df_total_yishuvs_last_5_years.apply(lambda x: calc_heuristic_score(x), axis=1)\n",
    "\n",
    "df_total_yishuvs_last_5_years = df_total_yishuvs_last_5_years.sort_values('prat_score', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_yishuvs_first_5_years.columns = [c + '_13_18' for c in df_total_yishuvs_first_5_years.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_yishuvs_last_5_years.columns = [c + '_18_23' for c in df_total_yishuvs_last_5_years.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_yishuvs_per_5_years_group = pd.concat([df_total_yishuvs_first_5_years, df_total_yishuvs_last_5_years], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_yishuvs_per_5_years_group['%change_prat'] = 100 * (df_all_yishuvs_per_5_years_group['prat_score_18_23'] - df_all_yishuvs_per_5_years_group['prat_score_13_18']) / df_all_yishuvs_per_5_years_group['prat_score_13_18']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_yishuvs_first_5_years.to_csv(os.path.join(schools_2023_results_directory,'scores_per_yishuv_first_5_years.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_yishuvs_last_5_years.to_csv(os.path.join(schools_2023_results_directory,'scores_per_yishuv_last_5_years.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_yishuvs_per_5_years_group.to_csv(os.path.join(schools_2023_results_directory,'scores_per_yishuv_5_years_periods.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_yishuvs_per_5_years_group_top_20_prat_18_23 = df_all_yishuvs_per_5_years_group.sort_values('prat_score_18_23', ascending=False)[0:20].sort_values('%change_prat', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_yishuvs_per_5_years_group_top_20_prat_18_23.to_csv(os.path.join(schools_2023_results_directory,'scores_per_yishuv_5_years_periods_top_20_prat_18_23_sorted_diff_prat.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dict_for_prat(df):\n",
    "    killed = df.loc[df.loc[:,'injury_severity'] == 1].inv_unique_id.nunique()\n",
    "    severe_injured = df.loc[df.loc[:,'injury_severity'] == 2].inv_unique_id.nunique()\n",
    "    light_injured = df.loc[df.loc[:,'injury_severity'] == 3].inv_unique_id.nunique()\n",
    "    total_accidents = df.acc_unique_id.nunique()\n",
    "    \n",
    "    final_dict = {\"accidents_count\": total_accidents,\n",
    "                  \"light_injured_count\": light_injured,\n",
    "                  \"severe_injured_count\": severe_injured,\n",
    "                  \"killed_count\": killed}\n",
    "    return final_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_poly_school_ids(yiushuv_name):\n",
    "    print(yiushuv_name)\n",
    "    df_yishuv_top_50_prat_schools = df_total[df_total.index.get_level_values('school_yishuv_name').isin([yiushuv_name])][0:50]\n",
    "    final_combs_with_scores = []\n",
    "    comb_size = df_yishuv_top_50_prat_schools.shape[0]\n",
    "    if comb_size == 0:\n",
    "        return []\n",
    "    elif comb_size > 3:\n",
    "        comb_size = 3\n",
    "    else:\n",
    "        pass\n",
    "    all_school_ids = set(itertools.combinations(df_yishuv_top_50_prat_schools.index.values, comb_size))\n",
    "    all_school_ids = [list(item) for item in set(tuple(row) for row in all_school_ids)]\n",
    "    for comb in tqdm(all_school_ids):\n",
    "        school_ids = [comb[0][1], comb[1][1], comb[2][1]]\n",
    "        df_curr = df_last_5_years.loc[df_last_5_years.school_id.isin(school_ids)]\n",
    "        prat_dict = calc_dict_for_prat(df_curr)\n",
    "        prat_score = calc_prat_score(prat_dict)\n",
    "        final_combs_with_scores.append({\"school_ids\": school_ids,\n",
    "                                        \"prat_score\": prat_score})\n",
    "    school_ids_final = pd.DataFrame(final_combs_with_scores).sort_values('prat_score', ascending=False)['school_ids'].iloc[0]\n",
    "    return school_ids_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_school_ids_final = top_20_yishuvs.swifter.apply(lambda x: get_final_poly_school_ids(x['school_yishuv_name']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_school_ids_final = poly_school_ids_final.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create final tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_no_idx = df_total.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(latitude, longitude, distance_in_km):\n",
    "    latitude = math.radians(latitude)\n",
    "    longitude = math.radians(longitude)\n",
    "\n",
    "    radius = 6371\n",
    "    # Radius of the parallel at given latitude\n",
    "    parallel_radius = radius * math.cos(latitude)\n",
    "\n",
    "    lat_min = latitude - distance_in_km / radius\n",
    "    lat_max = latitude + distance_in_km / radius\n",
    "    lon_min = longitude - distance_in_km / parallel_radius\n",
    "    lon_max = longitude + distance_in_km / parallel_radius\n",
    "    rad2deg = math.degrees\n",
    "\n",
    "    return rad2deg(lat_min), rad2deg(lon_min), rad2deg(lat_max), rad2deg(lon_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relevant_schools = []\n",
    "for school_id in poly_school_ids_final:\n",
    "    center_lat, center_lon = df_total_no_idx.loc[df_total_no_idx.school_id == school_id, ['school_latitude', 'school_longitude']].values[0]\n",
    "    lat_min, lon_min, lat_max, lon_max = get_bounding_box(center_lat, center_lon, 0.5)\n",
    "    baseX = lon_min\n",
    "    baseY = lat_min\n",
    "    distanceX = lon_max\n",
    "    distanceY = lat_max\n",
    "\n",
    "    poly = Polygon([(baseX, baseY), \n",
    "                    (baseX, distanceY),\n",
    "                    (distanceX, distanceY),\n",
    "                    (distanceX, baseY)])\n",
    "    bnbr_schools = df_total_no_idx.drop_duplicates(['school_id','school_longitude', 'school_latitude']).loc[:,['school_id','school_longitude', 'school_latitude']].to_dict(orient='records')\n",
    "    schools_in_1km_box = [r['school_id'] for r in bnbr_schools if poly.contains(Point(r['school_longitude'], r['school_latitude']))]\n",
    "    all_relevant_schools += schools_in_1km_box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polygons of final schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polygons_csv = df_total_no_idx.loc[df_total_no_idx.school_id.isin(poly_school_ids_final), ['WKT Polygon',\n",
    "                                                                                                'school_yishuv_name',\n",
    "                                                                                                'school_name',\n",
    "                                                                                                'prat_score',\n",
    "                                                                                                'killed_count',\n",
    "                                                                                                'severe_injured_count',\n",
    "                                                                                                'light_injured_count',\n",
    "                                                                                                'total_injured_count',\n",
    "                                                                                                'pedestrians',\n",
    "                                                                                                'bike',\n",
    "                                                                                                'electric_bike',\n",
    "                                                                                                'electric_korki',\n",
    "                                                                                                'accidents_count']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polygons_csv['WKT'] = final_polygons_csv['WKT Polygon'].apply(lambda x: x.replace(\",\", \", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = ['WKT', \n",
    "                 'school_name',\n",
    "                 'school_yishuv_name',\n",
    "                 'prat_score',\n",
    "                 'killed_count',\n",
    "                 'severe_injured_count',\n",
    "                 'light_injured_count',\n",
    "                 'total_injured_count',\n",
    "                 'pedestrians',\n",
    "                 'bike',\n",
    "                 'electric_bike',\n",
    "                 'electric_korki',\n",
    "                 'accidents_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polygons_csv = final_polygons_csv.loc[:, relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polygons_csv['school_name'] = 'מקבץ ' + final_polygons_csv['school_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polygons_csv['prat_score'] = final_polygons_csv['prat_score'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_hebrew_cols = ['WKT',\n",
    "                  'שם מקבץ',\n",
    "                  'ישוב',\n",
    "                  'דירוג',\n",
    "                  'סה״כ הרוגים במקבץ',\n",
    "                  'סה״כ פצועים קשה במקבץ',\n",
    "                  'סה״כ פצועים קל במקבץ',\n",
    "                  'סה״כ נפגעים והרוגים',\n",
    "                  'סה״כ הולכי רגל נפגעים',\n",
    "                  'סה״כ נפגעים רוכבי אופניים',\n",
    "                  'סה״כ נפגעים רוכבי אופניים חשמלים',\n",
    "                  'סה״כ נפגעים רוכבי קורקינט חשמלי',\n",
    "                  'מספר תאונות']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polygons_csv.columns = relevant_hebrew_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_polygons_csv.to_csv(os.path.join(schools_2023_results_directory, 'final_polygons_csv.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final schools and injured csvs for maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_schools_csv = df_total_no_idx.loc[df_total_no_idx.school_id.isin(all_relevant_schools), ['school_yishuv_name', 'school_name', 'school_longitude', 'school_latitude']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_schools_csv.columns = ['ישוב' , 'שם מוסד', 'longitude', 'latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_schools_csv.to_csv(os.path.join(schools_2023_results_directory, 'final_schools_csv.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv = df_last_5_years.loc[df_last_5_years.school_id.isin(all_relevant_schools), ['vehicle_or_pedestrian',  'injury_severity_hebrew', 'age_group_hebrew', 'accident_timestamp' ,'longitude', 'latitude', 'inv_unique_id']].drop_duplicates('inv_unique_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv = final_injured_csv.loc[:, ['vehicle_or_pedestrian', 'injury_severity_hebrew' ,'age_group_hebrew', 'accident_timestamp', 'longitude', 'latitude']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv.columns = ['סוג נפגע', 'חומרת פגיעה', 'קבוצת גיל','תאריך ושעה' ,'longitude', 'latitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove injured not in bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injured_idx_in_poly = set()\n",
    "for school_id in tqdm(poly_school_ids_final):\n",
    "    center_lat, center_lon = df_total_no_idx.loc[df_total_no_idx.school_id == school_id, ['school_latitude', 'school_longitude']].values[0]\n",
    "    lat_min, lon_min, lat_max, lon_max = get_bounding_box(center_lat, center_lon, 0.5)\n",
    "    baseX = lon_min\n",
    "    baseY = lat_min\n",
    "    distanceX = lon_max\n",
    "    distanceY = lat_max\n",
    "\n",
    "    poly = Polygon([(baseX, baseY), \n",
    "                    (baseX, distanceY),\n",
    "                    (distanceX, distanceY),\n",
    "                    (distanceX, baseY)])\n",
    "    injured = final_injured_csv.loc[:,['longitude', 'latitude']].to_dict(orient='index')\n",
    "    injured_idx = [k for k, v in injured.items() if poly.contains(Point(v['longitude'], v['latitude']))]\n",
    "    injured_idx_in_poly = injured_idx_in_poly.union(set(injured_idx))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv = final_injured_csv.loc[list(injured_idx_in_poly)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv.to_csv(os.path.join(schools_2023_results_directory, 'final_injured_csv.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv_light = final_injured_csv.loc[final_injured_csv['חומרת פגיעה'] == 'פצוע קל']\n",
    "\n",
    "final_injured_csv_light.to_csv(os.path.join(schools_2023_results_directory, 'final_injured_csv_light.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv_severe = final_injured_csv.loc[final_injured_csv['חומרת פגיעה'] == 'פצוע קשה']\n",
    "\n",
    "final_injured_csv_severe.to_csv(os.path.join(schools_2023_results_directory, 'final_injured_csv_severe.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_injured_csv_killed = final_injured_csv.loc[final_injured_csv['חומרת פגיעה'] == 'הרוג']\n",
    "\n",
    "final_injured_csv_killed.to_csv(os.path.join(schools_2023_results_directory, 'final_injured_csv_killed.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create jsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get all schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_data = json.load(open(\"/Users/atalya/Documents/anyway_main/repos/anyway/static/data/schools/schools_names.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schools_df = pd.DataFrame(schools_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schools_ids = all_schools_df.school_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### injured_around_schools_api_2023_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_df = df_last_5_years.copy()\n",
    "\n",
    "df_total_injured_schools_per_year = (\n",
    "    curr_df.groupby(\n",
    "        [\n",
    "            \"school_id\",\n",
    "            \"accident_year\",   \n",
    "            \"injury_severity\"\n",
    "        ]\n",
    "    )\n",
    "    .size()\n",
    "    .reset_index(name=\"injured_count\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_id\",\n",
    "            \"accident_year\",\n",
    "            \"injury_severity\",\n",
    "            \"injured_count\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "df_total_injured_schools_per_year = df_total_injured_schools_per_year.set_index(\n",
    "    [\n",
    "            \"school_id\",\n",
    "            \"accident_year\",   \n",
    "            \"injury_severity\"\n",
    "\n",
    "    ]\n",
    ").unstack(-1)\n",
    "df_total_injured_schools_per_year.fillna({\"injured_count\": 0, \"total_injured_count\": 0}, inplace=True)\n",
    "\n",
    "df_total_injured_schools_per_year.loc[:, (slice(\"injured_count\"), slice(None))] = df_total_injured_schools_per_year.loc[\n",
    "    :, (slice(\"injured_count\"), slice(None))\n",
    "].apply(lambda x: x.apply(int))\n",
    "\n",
    "df_total_injured_schools_per_year[\"total_injured_count\"] = (\n",
    "    df_total_injured_schools_per_year.loc[:, [\"injured_count\"]].sum(axis=1)\n",
    ").apply(int)\n",
    "\n",
    "df_total_injured_schools_per_year.columns = ['killed_count', 'severly_injured_count', 'light_injured_count', 'total_injured_killed_count']\n",
    "\n",
    "\n",
    "df_total_injured_schools_per_year = df_total_injured_schools_per_year.reset_index(drop=False).set_index('school_id')\n",
    "\n",
    "injured_schools_per_year_list = df_total_injured_schools_per_year.reset_index().to_dict(orient='records')\n",
    "\n",
    "school_ids = df_total_injured_schools_per_year.index.unique()\n",
    "\n",
    "total_dictionary_for_json_api = {}\n",
    "for school_id in all_schools_ids:\n",
    "    total_dictionary_for_json_api[str(school_id)] = [r for r in injured_schools_per_year_list if r[\"school_id\"] == school_id]\n",
    "with open(\"/Users/atalya/Documents/anyway_main/repos/anyway/static/data/schools/injured_around_schools_api_2023.json\", \"w\") as f:\n",
    "    json.dump(total_dictionary_for_json_api, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### injured_around_months_graph_data_api_2023_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_injured_schools_per_month = (\n",
    "    curr_df.groupby(\n",
    "        [\n",
    "            \"school_id\",\n",
    "            \"accident_month_hebrew\",   \n",
    "        ]\n",
    "    )\n",
    "    .size()\n",
    "    .reset_index(name=\"count_1\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_id\",\n",
    "            \"accident_month_hebrew\",\n",
    "            \"count_1\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "injured_schools_per_month_list = df_total_injured_schools_per_month.to_dict(orient='records')\n",
    "total_dictionary_for_json_api = {}\n",
    "for school_id in all_schools_ids:\n",
    "    total_dictionary_for_json_api[str(school_id)] = [r for r in injured_schools_per_month_list if r[\"school_id\"] == school_id]\n",
    "with open(\"/Users/atalya/Documents/anyway_main/repos/anyway/static/data/schools/injured_around_schools_months_graphs_data_api_2023.json\", \"w\") as f:\n",
    "    json.dump(total_dictionary_for_json_api, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### injured_around_sex_graph_data_api_2023_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_injured_schools_per_sex = (\n",
    "    curr_df.groupby(\n",
    "        [\n",
    "            \"school_id\",\n",
    "            \"sex_hebrew\",   \n",
    "        ]\n",
    "    )\n",
    "    .size()\n",
    "    .reset_index(name=\"count_1\")\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"school_id\",\n",
    "            \"sex_hebrew\",\n",
    "            \"count_1\",\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "injured_schools_per_sex_list = df_total_injured_schools_per_sex.to_dict(orient='records')\n",
    "total_dictionary_for_json_api = {}\n",
    "for school_id in all_schools_ids:\n",
    "    total_dictionary_for_json_api[str(school_id)] = [r for r in injured_schools_per_sex_list if r[\"school_id\"] == school_id]\n",
    "with open(\"/Users/atalya/Documents/anyway_main/repos/anyway/static/data/schools/injured_around_schools_sex_graphs_data_api_2023.json\", \"w\") as f:\n",
    "    json.dump(total_dictionary_for_json_api, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate ncr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "from functools import reduce\n",
    "\n",
    "def ncr(n, r):\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer // denom  # or / in Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncr(50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncr(100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncr(193,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
